{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93dbe0f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "repo_dir = os.environ.get(\"REPO_DIR\")\n",
    "code_dir = os.path.join(repo_dir, \"code/\")\n",
    "data_dir = os.path.join(repo_dir, \"data/\")\n",
    "os.chdir(code_dir)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import pickle\n",
    "import sklearn \n",
    "import sys\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import warnings\n",
    "\n",
    "from mosaiks.utils.imports import *\n",
    "\n",
    "# Key prediction functions are here\n",
    "from prediction_utils import (X_matrix_to_demeaned_X, df_to_demeaned_y_vars,\n",
    "make_train_pred_scatterplot as make_scatterplot, cv_solve, solver_kwargs, get_truth_preds_from_kfold_results,\n",
    "                             predict_y_from_kfold_dict, generalized_demean)\n",
    "\n",
    "\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from rasterio import warp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793724c",
   "metadata": {},
   "source": [
    "# NL Downscaling validation experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be916610",
   "metadata": {},
   "source": [
    "In this notebook we will try to predict mean DMSP nightlight luminosity at the ADM2 level, using a model trained at the ADM1 level. We use only MOSAIKS daytime image features in this experiment.\n",
    "\n",
    "This notebook requires the user to download all of the CGAZ python/pickle with population weights files from [mosaiks.org](mosaiks.org). Note that the ADM2 feature files is 3.5GB.\n",
    "\n",
    "Current page link is here: https://siml.berkeley.edu/portal/precomputed/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace44eec",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "770e36ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mosiaks features generated in the featurization pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feebff1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/lsherman/code_luke/hdi_downscaling/data/features/mosaiks_features/ADM_2_regions_RCF_global_dense_pop_weight=True.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_191647/2082922608.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmosaiks_features_direc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"features/mosaiks_features/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_adm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmosaiks_features_direc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"ADM_2_regions_RCF_global_dense_pop_weight=True.p\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_adm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmosaiks_features_direc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"ADM_2_regions_RCF_global_dense_aggregated_to_ADM1_pop_weight=True.p\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hdi/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     ) as handles:\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hdi/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/lsherman/code_luke/hdi_downscaling/data/features/mosaiks_features/ADM_2_regions_RCF_global_dense_pop_weight=True.p'"
     ]
    }
   ],
   "source": [
    "mosaiks_features_direc = data_dir + \"features/mosaiks_features/\"\n",
    "\n",
    "X_adm2 = pd.read_pickle(mosaiks_features_direc + \"ADM_2_regions_RCF_global_dense_pop_weight=True.p\")\n",
    "\n",
    "X_adm1 = pd.read_pickle(mosaiks_features_direc + \"ADM_2_regions_RCF_global_dense_aggregated_to_ADM1_pop_weight=True.p\")\n",
    "\n",
    "X_adm0 = pd.read_pickle(mosaiks_features_direc + \"ADM_2_regions_RCF_global_dense_aggregated_to_ADM0_pop_weight=True.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa1925",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_true_directory = data_dir + \"nl_downscaling/nl_Ys/\"\n",
    "\n",
    "y_adm2 = pd.read_pickle( nl_true_directory + \n",
    "                       \"dmsp_avg_nl_Ys_geoB_adm2.p\" ).astype(float)\n",
    "\n",
    "y_adm1 = pd.read_pickle(  nl_true_directory + \n",
    "                       \"dmsp_avg_nl_Ys_geoB_adm1.p\" ).astype(float) \n",
    "\n",
    "\n",
    "y_adm0 = pd.read_pickle(  nl_true_directory + \n",
    "                       \"dmsp_avg_nl_Ys_geoB_adm0.p\" ).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e8359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_df = gpd.read_file( (data_dir + \"raw/geoBoundaries/\"\n",
    "                        \"geoBoundariesCGAZ_ADM2.geojson\") )[[\"shapeID\",\"shapeGroup\",\"ADM1_shapeID\"]]\n",
    "\n",
    "link_df.rename(columns = {\"ADM1_shapeID\":\"ADM1_shape\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc235a",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d80a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up two tasks, pop weighted NL and average NL\n",
    "tasks = y_adm2.columns\n",
    "\n",
    "\n",
    "# Ireland has 50,000 ADM2 observations. Half the ADM2 dataset....\n",
    "drop_ireland = True\n",
    "\n",
    "extra_clip = True\n",
    "\n",
    "recenter_on = \"adm0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965b50e0",
   "metadata": {},
   "source": [
    "### Inspect missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ae825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some very small ADM1 regions that did not get assigned true NL vales\n",
    "\n",
    "# We will drop drop these\n",
    "# There are also a few obs with missing Xs\n",
    "print(y_adm1.drop(y_adm1.dropna().index))\n",
    "y_adm1.dropna(inplace=True)\n",
    "X_adm1 = X_adm1.loc[X_adm1.index.isin(y_adm1.index)]\n",
    "y_adm1 = y_adm1.loc[X_adm1.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5bd599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some a number of ADM2 regions that did not get assigned true NL vales\n",
    "# This is likley because they are outside the range of the raster data\n",
    "\n",
    "# There are also a few obs with missing Xs\n",
    "\n",
    "print(y_adm2.drop(y_adm2.dropna().index))\n",
    "y_adm2.dropna(inplace=True)\n",
    "\n",
    "X_adm2 = X_adm2.loc[X_adm2.index.isin(y_adm2.index)]\n",
    "y_adm2 = y_adm2.loc[X_adm2.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## There are 124 ADM2 polygons that have no parent ADM1 shape.\n",
    "## None of these even have y values at the adm2 level\n",
    "\n",
    "# 65 of these are associated with a Y. They must be dropped\n",
    "no_parent_ids = link_df[link_df[\"ADM1_shape\"].isnull()][\"shapeID\"]\n",
    "\n",
    "no_parent_ids_with_y = no_parent_ids[no_parent_ids.isin(y_adm2.index)]\n",
    "\n",
    "X_adm2.drop(no_parent_ids_with_y, inplace=True)\n",
    "y_adm2.drop(no_parent_ids_with_y, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are some ADM2 NL vals that do not have a parent y value.\n",
    "temp = y_adm2.merge(link_df,\"left\", left_index=True,right_on=\"shapeID\")\n",
    "temp = temp.merge(y_adm1, \"left\", left_on=\"ADM1_shape\", right_index=True)\n",
    "no_parent_y_idxs = temp[temp[\"nl_weighted_avg_y\"].isnull()][\"shapeID\"]\n",
    "\n",
    "\n",
    "X_adm2.drop(no_parent_y_idxs, inplace=True)\n",
    "y_adm2.drop(no_parent_y_idxs, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b75a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up two tasks, pop weighted NL and average NL\n",
    "tasks = y_adm2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d3fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = y_adm2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beedb88d",
   "metadata": {},
   "source": [
    "## Demean Xs and Ys for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e50f81",
   "metadata": {},
   "source": [
    "#### Demean Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### This step below is a bit confusing\n",
    "### We demean by the mean of the observations. the X_adm0 file is population weighted\n",
    "### We do not want to demean in a pop-weighted way. This matches our HDI procedure\n",
    "\n",
    "\n",
    "\n",
    "X_adm0_not_weighted =X_matrix_to_demeaned_X(X_adm1, return_mean_frame = True)\n",
    "\n",
    "X_adm1[\"shapeGroup\"] = pd.Series(X_adm1.index).apply(lambda x : x[:3]).to_numpy()\n",
    "X_adm1_demeaned = generalized_demean(X_adm1, X_adm0_not_weighted, \"shapeGroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adm2.drop(columns = \"shapeID\", inplace=True)\n",
    "X_adm2[\"shapeGroup\"] = pd.Series(X_adm2.index).apply(lambda x : x[:3]).to_numpy()\n",
    "X_adm2_demeaned = generalized_demean(X_adm2, X_adm0_not_weighted, \"shapeGroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca8464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_adm1.drop(columns = \"shapeGroup\", inplace=True)\n",
    "X_adm2.drop(columns = \"shapeGroup\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014145e0",
   "metadata": {},
   "source": [
    "#### Demean Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d659ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_adm1_shp = y_adm1.copy()\n",
    "y_adm1_shp[\"shapeGroup\"] = pd.Series(y_adm1_shp.index).apply(lambda x : x[:3]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a261ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_adm1_shp = y_adm1.copy()\n",
    "y_adm1_shp[\"shapeGroup\"] = pd.Series(y_adm1_shp.index).apply(lambda x : x[:3]).to_numpy()\n",
    "\n",
    "##### This step below is a bit confusing\n",
    "### We demean by the mean of the observations. the y_adm0 file is population weighted\n",
    "### We do not want to demean in a pop-weighted way. This matches our HDI procedure\n",
    "\n",
    "### WE use the mean of the ADM1 observations here. \n",
    "# This is VERY different than if we used the mean of the ADM2 observations..\n",
    "y_adm0_not_weighted = y_adm1_shp.groupby(\"shapeGroup\").mean()\n",
    "\n",
    "y_adm1_demeaned = generalized_demean(y_adm1_shp, y_adm0_not_weighted, \"shapeGroup\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12645ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_adm2_shp = y_adm2.copy()\n",
    "y_adm2_shp[\"shapeGroup\"] = pd.Series(y_adm2_shp.index).apply(lambda x : x[:3]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_adm2_shp = y_adm2.copy()\n",
    "y_adm2_shp[\"shapeGroup\"] = pd.Series(y_adm2_shp.index).apply(lambda x : x[:3]).to_numpy()\n",
    "y_adm2_demeaned = generalized_demean(y_adm2_shp, y_adm0_not_weighted, \"shapeGroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c1153",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the unweighted Y ADM1 data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce30fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_adm2_shp = y_adm2.copy()\n",
    "y_adm2_shp = y_adm2_shp.merge(link_df, \"left\", left_index=True, right_on=\"shapeID\")\n",
    "\n",
    "y_adm1_not_weighted = y_adm2_shp.groupby(\"ADM1_shape\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac46e3a",
   "metadata": {},
   "source": [
    "## Train ADM0 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b62758",
   "metadata": {},
   "source": [
    "### Getting overlapping indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d744e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = y_adm0\n",
    "X = X_adm0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae6594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_adm0 = len(y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282dc4b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adm0_kfold_dict = {}\n",
    "\n",
    "for task in tasks:\n",
    "    y = y_df[task].astype(float)\n",
    "    \n",
    "    adm0_kfold_dict[task] = cv_solve(task, \n",
    "                             X,\n",
    "                            y,\n",
    "                                 solver_kwargs = solver_kwargs,\n",
    "                             clip_bounds = [np.min(y), np.max(y)]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = (data_dir + \"model_data/dmsp_nl_model_adm0_model.pkl\")\n",
    "pickle.dump(adm0_kfold_dict, open(outpath, \"wb\"))\n",
    "\n",
    "adm0_kfold_dict = pickle.load(open(outpath, \"rb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c269f12",
   "metadata": {},
   "source": [
    "## Now let's calculate metrics\n",
    "\n",
    "Define key functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073180a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_preds_from_adm0_model_on_adm1_x(kfold_dict,task,X_for_pred,X_for_pred2=None):\n",
    "    \"\"\"\n",
    "    This function runs predictions from an ADM0 model on an ADM1 observation.\n",
    "    \n",
    "    It also ensures that ADM1 predictions are done from the model where the parent country was out of sample.\n",
    "    \n",
    "    Note that we do this for the ADM0 -> to ADM1 predictions, but have decided not to do this for ADM2 preds\n",
    "\n",
    "    (We ensure the that our preds are from within the CV folds)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    kfold_results = kfold_dict[task]\n",
    "    best_lam_idx  = ir.interpret_kfold_results(kfold_results, crits=\"r2_score\")[0][0][0]\n",
    "    \n",
    "    X_for_pred_countries = pd.Series(X_for_pred.index).apply(lambda x: x[:3])\n",
    "    \n",
    "    if X_for_pred2 is not None:\n",
    "        X_for_pred2 = kfold_results[\"rescale_X2\"] * X_for_pred2\n",
    "        \n",
    "        X_for_pred = pd.concat([X_for_pred,X_for_pred2],axis=1)\n",
    "    \n",
    "    stack = []\n",
    "    for i, test_country_array in enumerate(kfold_results[\"locations_test\"]):\n",
    "        test_country_array = pd.Series(test_country_array).apply(lambda x: x[:3]).to_numpy()\n",
    "        \n",
    "        idx_bools = X_for_pred_countries.isin(test_country_array).to_numpy()\n",
    "        test_set_df = X_for_pred[idx_bools]\n",
    "        \n",
    "        weights = kfold_results[\"models\"][i][0][best_lam_idx]\n",
    "        intercept = kfold_results[\"intercepts\"][i][0][best_lam_idx]\n",
    "        preds = test_set_df.dot(weights) + intercept\n",
    "        stack.append(preds)\n",
    "        \n",
    "    output = pd.concat(stack).sort_index()\n",
    "    output = output.clip(*kfold_results[\"clip_bounds\"])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c38c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nl_pred_truth_to_metrics_at_ADM1(preds, truth, task, link_df=link_df, demeaned_input=False, \n",
    "                                     adm0_unweighted_from_adm1_obs = y_adm0_not_weighted, return_df=False):\n",
    "    \n",
    "    df = pd.DataFrame([preds.rename(\"preds\"),truth.rename(\"truth\")]).T\n",
    "    \n",
    "    \n",
    "    df = df.merge(link_df.groupby(\"ADM1_shape\")[[\"shapeGroup\"]].first().reset_index() ,\"left\",left_index=True, \n",
    "                  right_on=\"ADM1_shape\")\n",
    "    \n",
    "    ### Note that this ADM0 Y is different than the pop weighted version that represents the True value.\n",
    "    ## This is the mean you get from the ADM1 observations\n",
    "    adm0 = adm0_unweighted_from_adm1_obs[task].rename(\"adm0_unweighted_true\")\n",
    "    df = df.merge(adm0, \"left\", left_on=\"shapeGroup\", right_index=True)\n",
    "    \n",
    "    if demeaned_input:\n",
    "        # For the demeaned inputs only, we add back the Ys that we had previously used for demeaning\n",
    "        df[\"preds\"] = df[\"preds\"] + df[\"adm0_unweighted_true\"]\n",
    "        df[\"truth\"] = df[\"truth\"] + df[\"adm0_unweighted_true\"]\n",
    "    \n",
    "    # Clip predictions to known min and max of range\n",
    "    df[\"preds\"] = np.clip(df[\"preds\"],0,63)\n",
    "    df = df.merge(y_adm0, \"left\", left_on=\"shapeGroup\", right_index=True)\n",
    "    \n",
    "    adm0_preds = df.groupby(\"shapeGroup\")[\"preds\"].mean().rename(\"adm0_unweighted_preds\")\n",
    "    df = df.merge(adm0_preds,\"left\", left_on=\"shapeGroup\", right_index=True)\n",
    "    \n",
    "    df[\"preds_demean_adm0\"] = (df[\"preds\"] - df[\"adm0_unweighted_preds\"]).astype(float)\n",
    "    df[\"true_demean_adm0\"] = (df[\"truth\"] - df[\"adm0_unweighted_true\"]).astype(float)\n",
    "    \n",
    "    \n",
    "    r2 = sklearn.metrics.r2_score(df[\"truth\"],df[\"preds\"])\n",
    "    pearson = np.corrcoef(df[\"truth\"],df[\"preds\"])[0,1] ** 2\n",
    "    spearman = spearmanr(df[\"truth\"],df[\"preds\"]).correlation\n",
    "\n",
    "    within_r2 = sklearn.metrics.r2_score(df[\"true_demean_adm0\"],df[\"preds_demean_adm0\"])\n",
    "    within_pearson = np.corrcoef(df[\"true_demean_adm0\"],df[\"preds_demean_adm0\"])[0,1]  ** 2\n",
    "    within_spearman = spearmanr(df[\"true_demean_adm0\"],df[\"preds_demean_adm0\"]).correlation\n",
    "\n",
    "\n",
    "    output_dict = {\"pearson\" : pearson, \"spearman\" : spearman, \"r2\" : r2,\n",
    "                   \"within_adm0_pearson\": within_pearson, \"within_adm0_spearman\": within_spearman, \"within_adm0_r2\":within_r2,\n",
    "                  }\n",
    "    if return_df:\n",
    "        return df\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e4eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nl_pred_truth_to_metrics_at_ADM2(preds, truth, task, link_df=link_df, demeaned_input=False,\n",
    "                                    adm0_unweighted_from_adm1_obs = y_adm0_not_weighted, \n",
    "                                    return_df=False, y_adm1_known = y_adm1, recenter_on=None, extra_clip=False,\n",
    "                                    drop_ireland=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to calculate all metrics for adm2 level predictions\n",
    "    \n",
    "    For the demaned models, we may want to recenter. Recenter options are as follows:\n",
    "    \n",
    "    recenter_on = \"adm0\", \"adm1\", or \"adm1_ideal\"\n",
    "\n",
    "    adm0 - Add back the country mean for a demeaned model. (Mean of ADM1 obs, not the pop weighted country value)\n",
    "    adm1 - Force the mean of the DHS observations to match the ADM1 observed value for the parent polygon\n",
    "    \n",
    "    adm1_ideal -  calculate the mean of adm2_observations aggregated to the adm1 level. Ensure these match for the truth\n",
    "                    and the preds. We cannot do this in practice, because we imagine that we do not know the truth.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame([preds.rename(\"preds\"),truth.rename(\"truth\")]).T\n",
    "    \n",
    "    df = df.merge(link_df ,\"left\",left_index=True, right_on=\"shapeID\")\n",
    "    \n",
    "    ### Note that this ADM0 Y is different than the pop weighted version that represents the True value.\n",
    "    ## This is the mean you get from an unweighted average of the ADM1 observations. This is also what we use\n",
    "    ## when we demean the observed Ys\n",
    "\n",
    "    adm0 = adm0_unweighted_from_adm1_obs[task].rename(\"adm0_unweighted_true_from_adm1_obs\")\n",
    "    df = df.merge(adm0, \"left\", left_on=\"shapeGroup\", right_index=True)\n",
    "    \n",
    "    df = df.merge(y_adm1[task].rename(\"adm1_known\"), how=\"left\", left_on = \"ADM1_shape\", right_index=True)\n",
    "    \n",
    "    if demeaned_input:\n",
    "        df[\"truth\"] = df[\"truth\"] + df[\"adm0_unweighted_true_from_adm1_obs\"]\n",
    "    \n",
    "    if demeaned_input and recenter_on==\"adm0\":\n",
    "        df[\"preds\"] = df[\"preds\"] + df[\"adm0_unweighted_true_from_adm1_obs\"]\n",
    "    \n",
    "    elif recenter_on == \"adm0\":\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    if recenter_on == \"adm1\":\n",
    "        adm1_unweighted_from_adm2_obs = df.groupby(\"ADM1_shape\").mean()[[\"preds\"]].rename(columns = {\n",
    "        \"preds\" : \"adm1_unweighted_mean_of_preds_from_adm2_obs\"} )\n",
    "        \n",
    "        df = df.merge(adm1_unweighted_from_adm2_obs,\"left\", left_on=\"ADM1_shape\", right_index=True)\n",
    "        \n",
    "        df[\"adm1_recentering_adj\"] = df[\"adm1_known\"] - df[\"adm1_unweighted_mean_of_preds_from_adm2_obs\"]\n",
    "        df[\"preds\"] = df[\"adm1_recentering_adj\"] + df[\"preds\"]\n",
    "        \n",
    "        df.drop(columns = [\n",
    "                   \"adm1_unweighted_mean_of_preds_from_adm2_obs\"], inplace=True)\n",
    "    \n",
    "    if recenter_on == \"adm1_ideal\":\n",
    "        adm1_unweighted_from_adm2_obs = df.groupby(\"ADM1_shape\").mean()[[\"truth\",\"preds\"]].rename(columns = {\n",
    "            \"truth\": \"adm1_unweighted_mean_of_truth_from_adm2_obs\", \"preds\" : \"adm1_unweighted_mean_of_preds_from_adm2_obs\"} )\n",
    "        df = df.merge(adm1_unweighted_from_adm2_obs,\"left\", left_on=\"ADM1_shape\", right_index=True)\n",
    "        df[\"adj_ideal\"] = df[\"adm1_unweighted_mean_of_truth_from_adm2_obs\"] - df[\"adm1_unweighted_mean_of_preds_from_adm2_obs\"]\n",
    "        df[\"preds\"] = df[\"adj_ideal\"] + df[\"preds\"]\n",
    "        \n",
    "        df.drop(columns = [\"adm1_unweighted_mean_of_truth_from_adm2_obs\",\n",
    "                           \"adm1_unweighted_mean_of_preds_from_adm2_obs\"], inplace=True)\n",
    "        \n",
    "    \n",
    "    # Clip predictions to known min and max of range. We do this after re-centering because the recentering procedure\n",
    "    # can result in values outside these bounds\n",
    "    if extra_clip:\n",
    "        print(\"Clipping changes: \", ( (df[\"preds\"]>63) | (df[\"preds\"]<0 )).sum()/len(df) *100, \"% of obs\")\n",
    "        print(\"Clipping too high: \", ( (df[\"preds\"]>63)).sum()/len(df) *100, \"% of obs\")\n",
    "        print(\"Clipping too low: \", ( (df[\"preds\"]<0)).sum()/len(df) *100, \"% of obs\")\n",
    "        df[\"preds\"] = np.clip(df[\"preds\"],0,63)\n",
    "        \n",
    "    if drop_ireland:\n",
    "        df = df[df[\"shapeGroup\"]!=\"IRL\"]\n",
    "    \n",
    "    ## Calculate metrics\n",
    "    r2 = sklearn.metrics.r2_score(df[\"truth\"],df[\"preds\"])\n",
    "    print(\"r2 = \", r2)\n",
    "    pearson = np.corrcoef(df[\"truth\"],df[\"preds\"])[0,1]**2\n",
    "    spearman = spearmanr(df[\"truth\"],df[\"preds\"]).correlation\n",
    "    \n",
    "    \n",
    "    ## Now we calculate the within-ADM0 mean. To do this, we need the ADM0 means as calculated \n",
    "    # from the ADM2 observations (no pop weighting)\n",
    "    adm0_unweighted_from_adm2_obs = df.groupby(\"shapeGroup\").mean()[[\"truth\",\"preds\"]].rename(columns ={\n",
    "        \"truth\":\"adm0_unweighted_mean_of_truth_from_adm2_obs\", \"preds\":\"adm0_unweighted_mean_of_preds_from_adm2_obs\"})\n",
    "    df = df.merge(adm0_unweighted_from_adm2_obs, \"left\", left_on=\"shapeGroup\", right_index=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "      ## Now we calculate the within-ADM1 mean. To do this, we need the ADM1 means as calculated \n",
    "    # from the ADM2 observations (no pop weighting)\n",
    "    adm1_unweighted_from_adm2_obs = df.groupby(\"ADM1_shape\").mean()[[\"truth\",\"preds\"]].rename(columns = {\n",
    "            \"truth\": \"adm1_unweighted_mean_of_truth_from_adm2_obs\", \"preds\" : \"adm1_unweighted_mean_of_preds_from_adm2_obs\"} )\n",
    "    df = df.merge(adm1_unweighted_from_adm2_obs,\"left\", left_on=\"ADM1_shape\", right_index=True)\n",
    "        \n",
    "    \n",
    "    ### Now we evaluate within-ADM0 performance. Note that what we actually substract here is different than \n",
    "    ## what we use when predicting at the ADM1 level. The mean of \"adm0_unweighted_true\" is zero. If we substract\n",
    "    # the unweighted mean of the adm1 observations, the mean is not zero.\n",
    "    \n",
    "    df[\"preds_demean_adm0\"] = (df[\"preds\"] - df[\"adm0_unweighted_mean_of_preds_from_adm2_obs\"]).astype(float)\n",
    "    df[\"true_demean_adm0\"] = (df[\"truth\"] - df[\"adm0_unweighted_mean_of_truth_from_adm2_obs\"]).astype(float)\n",
    "    \n",
    "    \n",
    "    within_r2 = sklearn.metrics.r2_score(df[\"true_demean_adm0\"],df[\"preds_demean_adm0\"])\n",
    "    within_pearson = np.corrcoef(df[\"true_demean_adm0\"],df[\"preds_demean_adm0\"])[0,1]  **2\n",
    "    within_spearman = spearmanr(df[\"true_demean_adm0\"],df[\"preds_demean_adm0\"]).correlation\n",
    "\n",
    "    \n",
    "    ### Now we evaluate within-ADM1 performance.\n",
    "    ### We demean by the calculated mean of the ADM2 observations. We can ask how much of the variation in ADM2 observations\n",
    "    ## is explained by the model. Under this procedure, the \"true_demean_adm1\" is centered on 0.\n",
    "    \n",
    "    df[\"preds_demean_adm1\"] = (df[\"preds\"] - df[\"adm1_unweighted_mean_of_preds_from_adm2_obs\"]).astype(float)\n",
    "    df[\"true_demean_adm1\"] = (df[\"truth\"] - df[\"adm1_unweighted_mean_of_truth_from_adm2_obs\"]).astype(float)\n",
    "\n",
    "    \n",
    "    within_r2_adm1 = sklearn.metrics.r2_score(df[\"true_demean_adm1\"],df[\"preds_demean_adm1\"])\n",
    "    within_pearson_adm1 = np.corrcoef(df[\"true_demean_adm1\"],df[\"preds_demean_adm1\"])[0,1]  ** 2\n",
    "    within_spearman_adm1 = spearmanr(df[\"true_demean_adm1\"],df[\"preds_demean_adm1\"]).correlation\n",
    "    \n",
    "\n",
    "    output_dict = {\"pearson\" : pearson, \"spearman\" : spearman, \"r2\" : r2,\n",
    "                   \"within_adm0_pearson\": within_pearson, \"within_adm0_spearman\": within_spearman, \"within_adm0_r2\":within_r2,\n",
    "                  \"within_adm1_pearson\": within_pearson_adm1, \"within_adm1_spearman\": within_spearman_adm1, \"within_adm1_r2\":within_r2_adm1,\n",
    "                  }\n",
    "    \n",
    "    \n",
    "    assert round(df[\"true_demean_adm1\"].mean(),6) ==0\n",
    "    assert round(df[\"true_demean_adm0\"].mean(),6) ==0\n",
    "    \n",
    "    assert round(df[\"preds_demean_adm1\"].mean(),6) ==0\n",
    "    assert round(df[\"preds_demean_adm0\"].mean(),6) ==0\n",
    "    \n",
    "    if return_df: \n",
    "        return df\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c5fc78",
   "metadata": {},
   "source": [
    "### Evaluate at ADM1 level (within CV folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fdea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "adm0_to_adm1_perf_dict = {}\n",
    "\n",
    "for task in tasks:\n",
    "\n",
    "    preds = run_preds_from_adm0_model_on_adm1_x(adm0_kfold_dict,task, X_adm1)\n",
    "    truth = y_adm1[task]\n",
    "    \n",
    "    adm0_to_adm1_perf_dict[task] = nl_pred_truth_to_metrics_at_ADM1(preds, truth, task)\n",
    "\n",
    "n_eval_adm1 = len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4c95c4",
   "metadata": {},
   "source": [
    "### Evaluate at ADM2 level (no longer within CV folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2807d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adm0_to_adm2_perf_dict = {}\n",
    "\n",
    "for task in tasks:\n",
    "\n",
    "    preds = predict_y_from_kfold_dict(X_adm2,adm0_kfold_dict,task)\n",
    "    truth = y_adm2.loc[preds.index, task]\n",
    "    \n",
    "    adm0_to_adm2_perf_dict[task] = nl_pred_truth_to_metrics_at_ADM2(preds, truth, task, drop_ireland=drop_ireland)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af011c63",
   "metadata": {},
   "source": [
    "## Repeat with ADM1 trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686630b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = y_adm1\n",
    "\n",
    "X = X_adm1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc5497",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08ce250",
   "metadata": {},
   "outputs": [],
   "source": [
    "adm1_kfold_dict = {}\n",
    "\n",
    "for task in tasks:\n",
    "    y = y_df[task].astype(float)\n",
    "    \n",
    "    adm1_kfold_dict[task] = cv_solve(task, \n",
    "                             X,\n",
    "                            y,\n",
    "                                 solver_kwargs = solver_kwargs,\n",
    "                             clip_bounds = [np.min(y), np.max(y)],\n",
    "                                     country_fold=True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72fdfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = (data_dir + \"model_data/dmsp_nl_model_adm1_model.pkl\")\n",
    "pickle.dump(adm1_kfold_dict, open(outpath, \"wb\"))\n",
    "\n",
    "adm1_kfold_dict = pickle.load(open(outpath, \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31289b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_adm1 = len(y_adm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e9b5c6",
   "metadata": {},
   "source": [
    "### Evaluate at ADM1 level (within CV folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94037ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adm1_to_adm1_perf_dict = {}\n",
    "\n",
    "for task in tasks:\n",
    "\n",
    "    truth, preds = get_truth_preds_from_kfold_results(adm1_kfold_dict[task])\n",
    "    \n",
    "    locs = np.hstack(adm1_kfold_dict[task][\"locations_test\"])\n",
    "    truth = pd.Series(truth.flatten(), index =locs)\n",
    "    preds = pd.Series(preds.flatten(), index =locs)\n",
    "    \n",
    "    adm1_to_adm1_perf_dict[task] = nl_pred_truth_to_metrics_at_ADM1(preds,truth, task)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aee259e",
   "metadata": {},
   "source": [
    "### Evlauate at ADM2 level (no longer evaluating within CV folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d0688",
   "metadata": {},
   "outputs": [],
   "source": [
    "adm1_to_adm2_perf_dict = {}\n",
    "\n",
    "for task in tasks:\n",
    "\n",
    "    preds = predict_y_from_kfold_dict(X_adm2, adm1_kfold_dict, task)\n",
    "    truth = y_adm2[task]\n",
    "    \n",
    "    adm1_to_adm2_perf_dict[task] = nl_pred_truth_to_metrics_at_ADM2(preds, truth, task, drop_ireland=drop_ireland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb818ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_adm2 = len(preds)\n",
    "if drop_ireland:\n",
    "    n_eval_adm2 = (~preds.index.str.startswith(\"IRL\")).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc083f",
   "metadata": {},
   "source": [
    "## Now we just repeat for the ADM1 demeaned by ADM0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8215e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = y_adm1_demeaned\n",
    "\n",
    "X = X_adm1_demeaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c25c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_demean = len(y_adm1_demeaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cc0d7b",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d8f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demeaned_adm1_kfold_dict = {}\n",
    "\n",
    "for task in tasks:\n",
    "    y = y_df[task].astype(float)\n",
    "    \n",
    "    demeaned_adm1_kfold_dict[task] = cv_solve(task, \n",
    "                             X,\n",
    "                            y,\n",
    "                                 solver_kwargs = solver_kwargs,\n",
    "                             clip_bounds = [np.min(y), np.max(y)],\n",
    "                                     country_fold=True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd39dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = (data_dir + \"model_data/dmsp_nl_model_adm1_demeaned_by_adm0_model.p\")\n",
    "pickle.dump(demeaned_adm1_kfold_dict, open(outpath, \"wb\"))\n",
    "\n",
    "demeaned_adm1_kfold_dict = pickle.load(open(outpath, \"rb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc6e90",
   "metadata": {},
   "source": [
    "### Evaluate at ADM1 level (within CV folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ddc4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "demeaned_adm1_to_adm1_perf_dict = {}\n",
    "\n",
    "for task in tasks:\n",
    "\n",
    "    truth, preds = get_truth_preds_from_kfold_results(demeaned_adm1_kfold_dict[task])\n",
    "    \n",
    "    locs = np.hstack(demeaned_adm1_kfold_dict[task][\"locations_test\"])\n",
    "    truth = pd.Series(truth.flatten(), index =locs)\n",
    "    preds = pd.Series(preds.flatten(), index =locs)\n",
    "    \n",
    "    demeaned_adm1_to_adm1_perf_dict[task] = nl_pred_truth_to_metrics_at_ADM1(preds,truth, task, \n",
    "                                                                             demeaned_input=True, \n",
    "                                                                            return_df=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b27639",
   "metadata": {},
   "source": [
    "### Evaluate at ADM2 level (no longer within CV folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c33054",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "demean_adm1_to_adm2_perf_dict = {}\n",
    "\n",
    "for task in tasks:\n",
    "\n",
    "    preds = predict_y_from_kfold_dict(X_adm2_demeaned,demeaned_adm1_kfold_dict,task,)\n",
    "    truth = y_adm2_demeaned[task]\n",
    "    \n",
    "    demean_adm1_to_adm2_perf_dict[task] = nl_pred_truth_to_metrics_at_ADM2(preds, truth, task, demeaned_input=True, recenter_on=recenter_on, drop_ireland=drop_ireland,\n",
    "                                                                         adm0_unweighted_from_adm1_obs=y_adm0_not_weighted, extra_clip=extra_clip,\n",
    "                                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543f7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tasks[1] #pop weighted\n",
    "\n",
    "pred_directory = data_dir + \"preds/\"\n",
    "file = pred_directory + f\"nl_adm2_preds_recenter={recenter_on}_dropIreland={drop_ireland}_extra_clip={extra_clip}\"\n",
    "\n",
    "df = nl_pred_truth_to_metrics_at_ADM2(preds, truth, task, demeaned_input=True, recenter_on=recenter_on, drop_ireland=drop_ireland, return_df=True,\n",
    "                                                                         adm0_unweighted_from_adm1_obs=y_adm0_not_weighted, extra_clip=extra_clip,                                                                    )\n",
    "df.to_pickle(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fe1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb116989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = nl_pred_truth_to_metrics_at_ADM2(preds, truth, tasks[0], demeaned_input=True, extra_clip=True, recenter_on=\"adm1\",\n",
    "#                                                                          adm0_unweighted_from_adm1_obs=y_adm0_not_weighted,\n",
    "#                                                                           return_df=True, drop_ireland=True)\n",
    "# make_scatterplot(\"Demean by ADM1 scatter\",df[\"true_demean_adm1\"], df[\"preds_demean_adm1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = nl_pred_truth_to_metrics_at_ADM2(preds, truth, tasks[1], demeaned_input=True, extra_clip=False, recenter_on=\"adm1\",\n",
    "#                                                                          adm0_unweighted_from_adm1_obs=y_adm0_not_weighted,\n",
    "#                                                                           return_df=True, drop_ireland=False)\n",
    "# make_scatterplot(\"Demean by ADM1 scatter\",df[\"true_demean_adm1\"], df[\"preds_demean_adm1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6bf2a5",
   "metadata": {},
   "source": [
    "## Make table for NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dc4a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\"pearson\": \"$\\rho^{2}$\", \"spearman\":\"Spearman r\", \"r2\":\"$R^{2}$\",\n",
    "               \"within_adm0_pearson\": \"$\\rho^{2}$\", \"within_adm0_spearman\":\"Spearman r\", \"within_adm0_r2\":\"$R^{2}$\",\n",
    "               \"within_adm1_pearson\": \"$\\rho^{2}$\", \"within_adm1_spearman\":\"Spearman r\", \"within_adm1_r2\":\"$R^{2}$\",\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f583937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(task, level=\"adm2\"):\n",
    "    outcomes_dicts =[\n",
    "\n",
    "    adm0_to_adm1_perf_dict,\n",
    "    adm1_to_adm1_perf_dict,\n",
    "    demeaned_adm1_to_adm1_perf_dict ,\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "    outcomes = [outcome[task] for outcome in outcomes_dicts]\n",
    "\n",
    "    table = pd.DataFrame(outcomes)\n",
    "\n",
    "    outcomes_dicts2 =[\n",
    "\n",
    "    adm0_to_adm2_perf_dict,\n",
    "    adm1_to_adm2_perf_dict,\n",
    "    demean_adm1_to_adm2_perf_dict ,\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "    outcomes = [outcome[task] for outcome in outcomes_dicts2]\n",
    "\n",
    "\n",
    "    table  = pd.concat([table,pd.DataFrame(outcomes)],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    table = table.round(2)\n",
    "\n",
    "    table[table < 0] = \"$< 0$\"\n",
    "\n",
    "\n",
    "    table = table.rename(columns = rename_dict)\n",
    "\n",
    "\n",
    "    table.loc[0,\"NL\"] = \"\\textbf{Country level} \" +f\"(n={n_train_adm0})\"\n",
    "    table.loc[1,\"NL\"] = \"\\textbf{Province level} \" +  \"(n={:,})\".format(n_train_adm1)\n",
    "    table.loc[2,\"NL\"] = \"\\textbf{Within-country} \"+  \"(n={:,})\".format(n_train_demean)\n",
    "\n",
    "\n",
    "    table[\"\"] = \"MOSAIKS\"\n",
    "\n",
    "    table.loc[3] = \"\\textbf{Predicted at ADM1 level} \" +  \"(n={:,})\".format(n_eval_adm1)\n",
    "    table.iloc[3,6:] = \"\\textbf{Predicted at ADM2 level} \" +  \"(n={:,})\".format(n_eval_adm2)\n",
    "\n",
    "    table.loc[4] =\"\\emph{ADM1 performance}\"\n",
    "    table.iloc[4,3:6] = \"\\emph{Within-country performance}\"\n",
    "    table.iloc[4,6:9] = \"\\emph{ADM2 performance}\"\n",
    "    table.iloc[4,9:12] = \"\\emph{Within-country performance}\"\n",
    "    table.iloc[4,12:15] = \"\\emph{Within-province performance}\"\n",
    "    \n",
    "    if level == \"adm2\":\n",
    "        table = table.iloc[:,[6,8,9,11,12,14,15,16]]\n",
    "    elif level == \"adm1\":\n",
    "        table = table.iloc[:,[0,2,3,5,15,16]]\n",
    "    else: \n",
    "        return table\n",
    "\n",
    "    table.loc[5] = (\"(\" + pd.Series(np.arange(1,table.shape[1]+1)).astype(str) +\")\").to_numpy()\n",
    "\n",
    "    table = table.T.reset_index().set_index([3,4,\"index\",5])\n",
    "\n",
    "    tab = table.T\n",
    "\n",
    "    tab.columns.names = ([None, None, None,None])\n",
    "\n",
    "\n",
    "    table = tab.set_index([tab.columns[-2],tab.columns[-1]])\n",
    "\n",
    "\n",
    "    table.index.names = [\"\\textbf{ \\emph{NL trained at}}\", \"\\textbf{ \\emph{Features}}\"]\n",
    "\n",
    "    table = table.iloc[[2,1,0]]\n",
    "\n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b309b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = make_table(tasks[1])\n",
    "\n",
    "\n",
    "print(table.to_latex(bold_rows=False,column_format=\"ll||cc|cc|cc\",\n",
    "     escape=False, multicolumn_format=\"c\")  )\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcfc1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = make_table(tasks[1], level=\"adm1\")\n",
    "\n",
    "\n",
    "print(table.to_latex(bold_rows=False,column_format=\"ll||cc|cc|cc\",\n",
    "     escape=False, multicolumn_format=\"c\")  )\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_table(tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feedaa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(table.iloc[:,np.arange(0,6)].to_latex(bold_rows=False,column_format=\"ll||ccc|ccc\",\n",
    "#       escape=False, multicolumn_format=\"c\")  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d2dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(table.to_latex(bold_rows=False,column_format=\"ll||ccc|ccc||ccc|ccc|ccc\",\n",
    "#       escape=False, multicolumn_format=\"c\")  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063de429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b79d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
