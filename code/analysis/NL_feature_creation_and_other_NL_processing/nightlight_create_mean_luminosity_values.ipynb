{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64134d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "repo_dir = os.environ.get(\"REPO_DIR\")\n",
    "code_dir = os.path.join(repo_dir, \"code/\")\n",
    "data_dir = os.path.join(repo_dir, \"data/\")\n",
    "os.chdir(code_dir)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import fiona\n",
    "\n",
    "from affine import Affine\n",
    "\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from rasterio import warp\n",
    "\n",
    "import warnings\n",
    "\n",
    "from nl_helpers import (apply_polygon_mask_and_return_flat_array, \n",
    "                        correct_nl_df_creation, bins,create_nl_binned_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b051a4",
   "metadata": {},
   "source": [
    "# For NL downscaling experiment, we want to get mean lumninosity values of various polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f244b8",
   "metadata": {},
   "source": [
    "### We need these for ADM2, ADM1, and ADM0 shapes. \n",
    "\n",
    "##### Since it's easy, we're going to get the pop weighted and the area weighted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deea1471",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_adj_to_nl_outpath = (data_dir + \"int/GPW_pop_density/\"\n",
    "           \"gpw_v4_population_density_rev10_2015_30_sec_shifted_to_match_DMSP.tif\")\n",
    "\n",
    "dmsp_adj_to_pop_outpath = (data_dir + \"int/DMSP_NL/\"\n",
    "           \"DMSP_F182013.v4c_web.stable_lights.avg_vis_shifted_to_match_pop_raster.tif\")\n",
    "\n",
    "nl_adj = rasterio.open(dmsp_adj_to_pop_outpath)\n",
    "pop_adj = rasterio.open(pop_adj_to_nl_outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "313b1ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_nl_and_weighted_avg_nl(shp_file,raster_file=nl_adj, weight_raster = pop_adj):\n",
    "    \n",
    "    for i, polygon in enumerate(shp_file[\"geometry\"]):\n",
    "        a = apply_polygon_mask_and_return_flat_array(polygon, plot=False, raster_file=raster_file)\n",
    "\n",
    "        w = apply_polygon_mask_and_return_flat_array(polygon, plot=False, raster_file=weight_raster)\n",
    "    \n",
    "        avg = np.mean(a)\n",
    "        \n",
    "        if len(w) == 0:\n",
    "            weighted_avg = None\n",
    "        else:\n",
    "            weighted_avg = np.average(a, weights=w)\n",
    "        \n",
    "        averages = np.array([avg, weighted_avg])\n",
    "\n",
    "        if i == 0:\n",
    "            stacked = averages\n",
    "        else:\n",
    "            stacked = np.vstack([stacked, averages])\n",
    "    \n",
    "    out = pd.DataFrame(stacked, index = shp_file.index)\n",
    "    out.columns =  [\"nl_avg\",\"nl_weighted_avg\"]\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b0fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_nl_Ys(out, shp_file, raster_file, bins = bins, off_raster_val=np.nan):\n",
    "    \"\"\"\n",
    "    Some of the ADM2 and other polygons are so small that we need to get the nearest NL pixel, \n",
    "    rather the consider the pixel to be contained by the polygon. This implements this correction.\n",
    "    \n",
    "    If the polygon has no intersection with the raster, we assume that it is well off the raster. \n",
    "    For these we, actually only input nan values by default.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    null_idxs = out[out.iloc[:,0].isnull()].index\n",
    "    \n",
    "    num_missing =  len(null_idxs)\n",
    "    print(\"Num missing = \", num_missing)\n",
    "    if num_missing == 0:\n",
    "        return out\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\") # suppress warnings for unprojected buffer\n",
    "        #Create buffer the centroid of the adm polygon, equivelant to calculating centroid to centroid nearest\n",
    "        buffers = shp_file.loc[null_idxs][\"geometry\"].centroid.buffer(0.00833333333333/2)\n",
    "    \n",
    "    \n",
    "    for i, buffer in enumerate(buffers):\n",
    "        \n",
    "        a = apply_polygon_mask_and_return_flat_array(buffer, raster_file = raster_file)\n",
    "        assert len(a) <= 1\n",
    "        \n",
    "        # if there is still no nl value being grabbed, it means we are off the raster. Assume 0\n",
    "        if len(a) == 0:\n",
    "            a = np.array([off_raster_val])\n",
    "            \n",
    "        avg = a[0]\n",
    "        averages = np.array([avg,avg]) # Weighted avereage and average are both just a.value\n",
    "        \n",
    "        if i == 0:\n",
    "            stacked = averages\n",
    "        else:\n",
    "            stacked = np.vstack([stacked, averages])\n",
    "            \n",
    "    fixed_out = pd.DataFrame(stacked, index = null_idxs)\n",
    "    \n",
    "    fixed_out.columns =  [\"nl_avg\",\"nl_weighted_avg\"]\n",
    "        \n",
    "    out_dropped = out.drop(null_idxs)\n",
    "        \n",
    "    return pd.concat([fixed_out,out_dropped])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adafec53",
   "metadata": {},
   "source": [
    "### ADM2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d83832",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = data_dir + \"raw/geoBoundaries/geoBoundariesCGAZ_ADM2.geojson\"\n",
    "adm2 = gpd.read_file(file).set_index(\"shapeID\").rename(columns = {\"ADM1_shapeID\": \"ADM1_shape\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c4ef5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsherman/miniconda3/envs/maps-env/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/lsherman/miniconda3/envs/maps-env/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num missing =  7058\n"
     ]
    }
   ],
   "source": [
    "out_adm2 = get_avg_nl_and_weighted_avg_nl(adm2, raster_file=nl_adj, weight_raster =pop_adj)\n",
    "out_adm2 = correct_nl_Ys(out_adm2, adm2, raster_file=nl_adj)\n",
    "\n",
    "out_adm2.to_pickle(data_dir + \"nl_downscaling/nl_Ys/dmsp_avg_nl_Ys_geoB_adm2.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d29d70",
   "metadata": {},
   "source": [
    "### ADM1 -- from ADM2 geoBoundaries shapefile dissolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "693377d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsherman/miniconda3/envs/maps-env/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/lsherman/miniconda3/envs/maps-env/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num missing =  7\n"
     ]
    }
   ],
   "source": [
    "adm1_geoboundaries = adm2.dissolve(\"ADM1_shape\")\n",
    "out_adm1 = get_avg_nl_and_weighted_avg_nl(adm1_geoboundaries, raster_file=nl_adj, weight_raster =pop_adj)\n",
    "out_adm1 = correct_nl_Ys(out_adm1, adm1_geoboundaries, raster_file=nl_adj)\n",
    "\n",
    "out_adm1.to_pickle(data_dir + \"nl_downscaling/nl_Ys/dmsp_avg_nl_Ys_geoB_adm1.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a541f963",
   "metadata": {},
   "source": [
    "### ADM0 -- from ADM2 geoBoundaries shapefile dissolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcbe3ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num missing =  0\n"
     ]
    }
   ],
   "source": [
    "adm0_geoboundaries = adm2.dissolve(\"shapeGroup\")\n",
    "out_adm0 = get_avg_nl_and_weighted_avg_nl(adm0_geoboundaries, raster_file=nl_adj, weight_raster =pop_adj)\n",
    "out_adm0 = correct_nl_Ys(out_adm0, adm0_geoboundaries, raster_file=nl_adj)\n",
    "out_adm0.to_pickle(data_dir + \"nl_downscaling/nl_Ys/dmsp_avg_nl_Ys_geoB_adm0.p\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74cc57e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
